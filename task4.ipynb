{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "train=pd.read_csv(\"electric_train.csv\")\n",
    "\n",
    "\n",
    "# drop first column\n",
    "train.drop(train.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"electric_test.csv\")\n",
    "# drop first column\n",
    "test.drop(test.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 electric_train.num\n",
      "1 electric_train.tm\n",
      "2 electric_train.hh24\n",
      "3 electric_train.n\n",
      "4 electric_train.stn\n",
      "5 electric_train.sum_qctr\n",
      "6 electric_train.sum_load\n",
      "7 electric_train.n_mean_load\n",
      "8 electric_train.nph_ta\n",
      "9 electric_train.nph_hm\n",
      "10 electric_train.nph_ws_10m\n",
      "11 electric_train.nph_rn_60m\n",
      "12 electric_train.nph_ta_chi\n",
      "13 electric_train.weekday\n",
      "14 electric_train.week_name\n",
      "15 electric_train.elec\n"
     ]
    }
   ],
   "source": [
    "train.columns\n",
    "for idx, col in enumerate(train.columns):\n",
    "    print(idx, col)\n",
    "    train.rename(columns={col: col.replace(\"electric_train.\", \"\")}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num', 'tm', 'hh24', 'n', 'stn', 'sum_qctr', 'sum_load', 'n_mean_load',\n",
       "       'nph_ta', 'nph_hm', 'nph_ws_10m', 'nph_rn_60m', 'nph_ta_chi', 'weekday',\n",
       "       'week_name', 'elec'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split datetime tm into date and time\n",
    "train['hour'] = pd.to_datetime(train['tm']).dt.hour   \n",
    "train['month'] = pd.to_datetime(train['tm']).dt.month\n",
    "train['day'] = pd.to_datetime(train['tm']).dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('tm', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>hh24</th>\n",
       "      <th>n</th>\n",
       "      <th>stn</th>\n",
       "      <th>sum_qctr</th>\n",
       "      <th>sum_load</th>\n",
       "      <th>n_mean_load</th>\n",
       "      <th>nph_ta</th>\n",
       "      <th>nph_hm</th>\n",
       "      <th>nph_ws_10m</th>\n",
       "      <th>nph_rn_60m</th>\n",
       "      <th>nph_ta_chi</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week_name</th>\n",
       "      <th>elec</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4821</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>884</td>\n",
       "      <td>6950</td>\n",
       "      <td>751.32</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>2.2</td>\n",
       "      <td>62.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>99.56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4821</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>884</td>\n",
       "      <td>6950</td>\n",
       "      <td>692.60</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>2.3</td>\n",
       "      <td>63.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>91.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4821</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>884</td>\n",
       "      <td>6950</td>\n",
       "      <td>597.48</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>2.2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>79.17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4821</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>884</td>\n",
       "      <td>6950</td>\n",
       "      <td>553.48</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>1.7</td>\n",
       "      <td>63.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>73.34</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4821</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>884</td>\n",
       "      <td>6950</td>\n",
       "      <td>526.24</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>1.7</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>69.73</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593350</th>\n",
       "      <td>20947</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>671</td>\n",
       "      <td>34200</td>\n",
       "      <td>6779.84</td>\n",
       "      <td>225.462000</td>\n",
       "      <td>2.7</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>130.74</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593351</th>\n",
       "      <td>20947</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>671</td>\n",
       "      <td>34200</td>\n",
       "      <td>6802.40</td>\n",
       "      <td>225.462000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>46.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>131.18</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593352</th>\n",
       "      <td>20947</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>671</td>\n",
       "      <td>34200</td>\n",
       "      <td>6706.68</td>\n",
       "      <td>225.462000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>47.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>129.33</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593353</th>\n",
       "      <td>20947</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>671</td>\n",
       "      <td>34200</td>\n",
       "      <td>6355.88</td>\n",
       "      <td>225.462000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>122.57</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593354</th>\n",
       "      <td>20947</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>671</td>\n",
       "      <td>34200</td>\n",
       "      <td>5969.72</td>\n",
       "      <td>225.462000</td>\n",
       "      <td>3.1</td>\n",
       "      <td>44.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>115.12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7593355 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           num  hh24   n  stn  sum_qctr  sum_load  n_mean_load  nph_ta  \\\n",
       "0         4821     1  11  884      6950    751.32    68.606449     2.2   \n",
       "1         4821     2  11  884      6950    692.60    68.606449     2.3   \n",
       "2         4821     3  11  884      6950    597.48    68.606449     2.2   \n",
       "3         4821     4  11  884      6950    553.48    68.606449     1.7   \n",
       "4         4821     5  11  884      6950    526.24    68.606449     1.7   \n",
       "...        ...   ...  ..  ...       ...       ...          ...     ...   \n",
       "7593350  20947    20  23  671     34200   6779.84   225.462000     2.7   \n",
       "7593351  20947    21  23  671     34200   6802.40   225.462000     2.6   \n",
       "7593352  20947    22  23  671     34200   6706.68   225.462000     2.4   \n",
       "7593353  20947    23  23  671     34200   6355.88   225.462000     2.5   \n",
       "7593354  20947    24  23  671     34200   5969.72   225.462000     3.1   \n",
       "\n",
       "         nph_hm  nph_ws_10m  nph_rn_60m  nph_ta_chi  weekday  week_name  \\\n",
       "0          62.7         1.8         0.0        -1.0        4          0   \n",
       "1          63.1         2.1         0.0        -0.6        4          0   \n",
       "2          62.4         2.5         0.0        -1.3        4          0   \n",
       "3          63.5         1.7         0.0        -0.2        4          0   \n",
       "4          63.0         1.6         0.0        -0.8        4          0   \n",
       "...         ...         ...         ...         ...      ...        ...   \n",
       "7593350    46.3         3.1         0.0        -0.4        5          1   \n",
       "7593351    46.8         3.1         0.0        -0.5        5          1   \n",
       "7593352    47.4         2.1         0.0         0.2        5          1   \n",
       "7593353    47.0         2.1         0.0         0.3        5          1   \n",
       "7593354    44.4         3.5         0.0        -1.9        6          1   \n",
       "\n",
       "           elec  hour  month  day  \n",
       "0         99.56     1      1    1  \n",
       "1         91.78     2      1    1  \n",
       "2         79.17     3      1    1  \n",
       "3         73.34     4      1    1  \n",
       "4         69.73     5      1    1  \n",
       "...         ...   ...    ...  ...  \n",
       "7593350  130.74    20     12   31  \n",
       "7593351  131.18    21     12   31  \n",
       "7593352  129.33    22     12   31  \n",
       "7593353  122.57    23     12   31  \n",
       "7593354  115.12     0      1    1  \n",
       "\n",
       "[7593355 rows x 18 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['sum_qctr','sum_load','n_mean_load'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./models\"\n",
      "Presets specified: ['medium_quality']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (7593355 samples, 820.08 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./models\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          12\n",
      "Memory Avail:       3.26 GB / 15.93 GB (20.5%)\n",
      "Disk Space Avail:   34.99 GB / 237.70 GB (14.7%)\n",
      "===================================================\n",
      "Train Data Rows:    7593355\n",
      "Train Data Columns: 14\n",
      "Label Column:       elec\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Tabular_complete========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3247.94 MB\n",
      "\tTrain Data (Original)  Memory Usage: 724.16 MB (22.3% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 22.3% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['nph_ta', 'nph_hm', 'nph_ws_10m', 'nph_rn_60m', 'nph_ta_chi']\n",
      "\t\t('int', [])   : 9 | ['num', 'hh24', 'n', 'stn', 'weekday', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 5 | ['nph_ta', 'nph_hm', 'nph_ws_10m', 'nph_rn_60m', 'nph_ta_chi']\n",
      "\t\t('int', [])       : 8 | ['num', 'hh24', 'n', 'stn', 'weekday', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['week_name']\n",
      "\t10.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 673.47 MB (10.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 11.65s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 7517421, Val Rows: 75934\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "}\n",
      "Fitting 5 L1 models ...\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 3.989 GB out of 4.959 GB available memory (80.433%)... (90.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.12 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 23.7281\n",
      "[2000]\tvalid_set's l2: 18.4396\n",
      "[3000]\tvalid_set's l2: 15.8905\n",
      "[4000]\tvalid_set's l2: 13.8829\n",
      "[5000]\tvalid_set's l2: 12.5966\n",
      "[6000]\tvalid_set's l2: 11.52\n",
      "[7000]\tvalid_set's l2: 10.6415\n",
      "[8000]\tvalid_set's l2: 9.94\n",
      "[9000]\tvalid_set's l2: 9.39342\n",
      "[10000]\tvalid_set's l2: 8.89453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-8.8945\t = Validation score   (-mean_squared_error)\n",
      "\t1011.95s\t = Training   runtime\n",
      "\t3.52s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 3.989 GB out of 3.673 GB available memory (108.585%)... (90.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.26 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train LightGBMXT... Skipping this model.\n",
      "Fitting model: CatBoost ...\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 3.992 GB out of 3.766 GB available memory (106.003%)... (100.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.11 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train CatBoost... Skipping this model.\n",
      "Fitting model: XGBoost ...\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 5.510 GB out of 3.814 GB available memory (144.453%)... (100.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.49 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train XGBoost... Skipping this model.\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 3.997 GB out of 3.815 GB available memory (104.771%)... (90.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.21 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train LightGBMLarge... Skipping this model.\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBM': 1.0}\n",
      "\t-8.8945\t = Validation score   (-mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1035.68s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./models\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================learning_complete========================\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "#train = pd.read_csv('../preprocess/q1_train_data_2.csv')\n",
    "#test = pd.read_csv('../preprocess/q1_test_data_2.csv')\n",
    "\n",
    "train_data = TabularDataset(train)\n",
    "#test_data = TabularDataset(test)\n",
    "\n",
    "print(\"==================Tabular_complete========================\")\n",
    "\n",
    "hyperparameters = {\n",
    "\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, 'GBMLarge'],\n",
    "\t'CAT': {},\n",
    "\t'XGB': {},\n",
    "}\n",
    "\n",
    "save_path = './models'\n",
    "predictor = TabularPredictor(label='elec', problem_type = 'regression', eval_metric='mean_squared_error',\n",
    "                            path = save_path)\n",
    "predictor.fit(train_data, hyperparameters=hyperparameters,presets='medium_quality')\n",
    "\n",
    "print(\"==================learning_complete========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-8.716142</td>\n",
       "      <td>-8.894532</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>339.398070</td>\n",
       "      <td>3.520025</td>\n",
       "      <td>1011.952992</td>\n",
       "      <td>339.398070</td>\n",
       "      <td>3.520025</td>\n",
       "      <td>1011.952992</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-8.716142</td>\n",
       "      <td>-8.894532</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>339.528188</td>\n",
       "      <td>3.521027</td>\n",
       "      <td>1011.964422</td>\n",
       "      <td>0.130118</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.011430</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val         eval_metric  \\\n",
       "0             LightGBM   -8.716142  -8.894532  mean_squared_error   \n",
       "1  WeightedEnsemble_L2   -8.716142  -8.894532  mean_squared_error   \n",
       "\n",
       "   pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  \\\n",
       "0      339.398070       3.520025  1011.952992               339.398070   \n",
       "1      339.528188       3.521027  1011.964422                 0.130118   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                3.520025        1011.952992            1       True   \n",
       "1                0.001002           0.011430            2       True   \n",
       "\n",
       "   fit_order  \n",
       "0          1  \n",
       "1          2  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['hour'] = pd.to_datetime(test['tm']).dt.hour\n",
    "test['month'] = pd.to_datetime(test['tm']).dt.month\n",
    "test['day'] = pd.to_datetime(test['tm']).dt.day\n",
    "test['n']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('tm', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>hh24</th>\n",
       "      <th>n</th>\n",
       "      <th>stn</th>\n",
       "      <th>nph_ta</th>\n",
       "      <th>nph_hm</th>\n",
       "      <th>nph_ws_10m</th>\n",
       "      <th>nph_rn_60m</th>\n",
       "      <th>nph_ta_chi</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week_name</th>\n",
       "      <th>elec</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4821</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>884</td>\n",
       "      <td>2.2</td>\n",
       "      <td>62.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>99.56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4821</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>884</td>\n",
       "      <td>2.3</td>\n",
       "      <td>63.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>91.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4821</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>884</td>\n",
       "      <td>2.2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>79.17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4821</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>884</td>\n",
       "      <td>1.7</td>\n",
       "      <td>63.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>73.34</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4821</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>884</td>\n",
       "      <td>1.7</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>69.73</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593350</th>\n",
       "      <td>20947</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>671</td>\n",
       "      <td>2.7</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>130.74</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593351</th>\n",
       "      <td>20947</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>671</td>\n",
       "      <td>2.6</td>\n",
       "      <td>46.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>131.18</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593352</th>\n",
       "      <td>20947</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>671</td>\n",
       "      <td>2.4</td>\n",
       "      <td>47.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>129.33</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593353</th>\n",
       "      <td>20947</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>671</td>\n",
       "      <td>2.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>122.57</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593354</th>\n",
       "      <td>20947</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>671</td>\n",
       "      <td>3.1</td>\n",
       "      <td>44.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>115.12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7593355 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           num  hh24   n  stn  nph_ta  nph_hm  nph_ws_10m  nph_rn_60m  \\\n",
       "0         4821     1  11  884     2.2    62.7         1.8         0.0   \n",
       "1         4821     2  11  884     2.3    63.1         2.1         0.0   \n",
       "2         4821     3  11  884     2.2    62.4         2.5         0.0   \n",
       "3         4821     4  11  884     1.7    63.5         1.7         0.0   \n",
       "4         4821     5  11  884     1.7    63.0         1.6         0.0   \n",
       "...        ...   ...  ..  ...     ...     ...         ...         ...   \n",
       "7593350  20947    20  23  671     2.7    46.3         3.1         0.0   \n",
       "7593351  20947    21  23  671     2.6    46.8         3.1         0.0   \n",
       "7593352  20947    22  23  671     2.4    47.4         2.1         0.0   \n",
       "7593353  20947    23  23  671     2.5    47.0         2.1         0.0   \n",
       "7593354  20947    24  23  671     3.1    44.4         3.5         0.0   \n",
       "\n",
       "         nph_ta_chi  weekday  week_name    elec  hour  month  day  \n",
       "0              -1.0        4          0   99.56     1      1    1  \n",
       "1              -0.6        4          0   91.78     2      1    1  \n",
       "2              -1.3        4          0   79.17     3      1    1  \n",
       "3              -0.2        4          0   73.34     4      1    1  \n",
       "4              -0.8        4          0   69.73     5      1    1  \n",
       "...             ...      ...        ...     ...   ...    ...  ...  \n",
       "7593350        -0.4        5          1  130.74    20     12   31  \n",
       "7593351        -0.5        5          1  131.18    21     12   31  \n",
       "7593352         0.2        5          1  129.33    22     12   31  \n",
       "7593353         0.3        5          1  122.57    23     12   31  \n",
       "7593354        -1.9        6          1  115.12     0      1    1  \n",
       "\n",
       "[7593355 rows x 15 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TabularDataset(test)\n",
    "y_pred = predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv('electric_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 electric_test.num\n",
      "1 electric_test.tm\n",
      "2 electric_test.hh24\n",
      "3 electric_test.stn\n",
      "4 electric_test.nph_ta\n",
      "5 electric_test.nph_hm\n",
      "6 electric_test.nph_ws_10m\n",
      "7 electric_test.nph_rn_60m\n",
      "8 electric_test.nph_ta_chi\n",
      "9 electric_test.weekday\n",
      "10 electric_test.week_name\n"
     ]
    }
   ],
   "source": [
    "for idx, col in enumerate(test.columns):\n",
    "    print(idx, col)\n",
    "    test.rename(columns={col: col.replace(\"electric_test.\", \"\")}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num', 'tm', 'hh24', 'stn', 'nph_ta', 'nph_hm', 'nph_ws_10m',\n",
       "       'nph_rn_60m', 'nph_ta_chi', 'weekday', 'week_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
